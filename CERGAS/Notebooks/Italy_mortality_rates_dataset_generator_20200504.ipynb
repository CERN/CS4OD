{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common standard libraries\n",
    "\n",
    "import datetime\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common external libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn # scikit-learn\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from time import sleep\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization libraries\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting plot appearance\n",
    "# See here for more options: https://matplotlib.org/users/customizing.html\n",
    "\n",
    "%config InlineBackend.figure_format='retina'\n",
    "sns.set() # Revert to matplotlib defaults\n",
    "plt.rcParams['figure.figsize'] = (9, 6)\n",
    "plt.rcParams['axes.labelpad'] = 10\n",
    "sns.set_style(\"darkgrid\")\n",
    "# sns.set_context(\"poster\", font_scale=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore warnings (don't display stderr)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Circular Health Project\n",
    "## Mortality Rate Analysis in Italy (2015-2020)\n",
    "## Dataset generator\n",
    "\n",
    "This notebook downloads and aggregates the mortality rates data file from a subset of municipalities in the ANPR system</br>\n",
    "and the municipality census information producing a derived dataset that contains population information and a better</br>\n",
    "feature sets for analysis. This version uses the ISTAT data format with M_XX, F_XX, T_XX features\n",
    "\n",
    "Source: https://www.istat.it/it/archivio/240401</br>\n",
    "Permasource: https://sandbox.zenodo.org/record/535730#.XrJ-v6gzaUk</br>\n",
    "\n",
    "Version: 1.0-20200504"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load the data from Zenodo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading mortality data file...\n",
      "Loaded 914621 records\n"
     ]
    }
   ],
   "source": [
    "# Load mortality data from ISTAT file\n",
    "print('Loading mortality data file...')\n",
    "mr_df = pd.read_csv(filepath_or_buffer='https://zenodo.org/record/3824313/files/comuni_giornaliero_20200504.csv?download=1', header=0, encoding='iso-8859-1')\n",
    "print('Loaded %d records' %len(mr_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "mr_df.head();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading municipalities population data file based on 2011 census ...\n",
      "Loaded 7904 records\n"
     ]
    }
   ],
   "source": [
    "# Load municipalities data from ISTAT file, synch colum names with mortality rates data\n",
    "print('Loading municipalities population data file based on 2011 census ...')\n",
    "md_df = pd.read_excel(io='https://zenodo.org/record/3824404/files/Elenco-codici-statistici-e-denominazioni-al-01_01_2020.xls?download=1',\n",
    "                names=['REG','UNI','PROV_STR','COM_STR','COD_PROVCOM_STR','NOME_COMUNE_INT','NOME_COMUNE','LINGUA','COD_RIP_GEO','RIP_GEO',\n",
    "                        'NOME_REGIONE','NOME_PROVINCIA','TIPO_COMUNE','SIGLA','COD_PROVCOM','COD_PROVCOM_2016','COD_PROVCOM_2009','COD_PROVCOM_2005',\n",
    "                        'COD_CAT','POPOLAZIONE','NUTS1','NUTS2(3)','NUTS3'])\n",
    "print('Loaded %d records' %len(md_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "md_df.head();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading municipalities population data file updates at January 1st, 2019...\n",
      "Loaded 808452 records\n"
     ]
    }
   ],
   "source": [
    "# Load municipalities data from ISTAT file, synch colum names with mortality rates data\n",
    "print('Loading municipalities population data file updates at January 1st, 2019...')\n",
    "md_df_2019 = pd.read_csv(filepath_or_buffer='https://zenodo.org/record/3824529/files/comuni-popolazione-residente-2019.csv?download=1', header=1, encoding='iso-8859-1')\n",
    "print('Loaded %d records' %len(md_df_2019))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "md_df_2019.head();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading municipalities geographical coordinates data file...\n",
      "Loaded 7979 records\n"
     ]
    }
   ],
   "source": [
    "# Load municipalities geographical coordinates\n",
    "print('Loading municipalities geographical coordinates data file...')\n",
    "geo_df = pd.read_excel(io='https://zenodo.org/record/3824502/files/italy_geo.xlsx?download=1', sheet_name='italy_geo')\n",
    "print('Loaded %d records' %len(geo_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_df.head();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Look at the data, clean, reorganize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify and NaNs\n",
    "mr_df.isnull().sum();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify and NaNs\n",
    "md_df.isnull().sum();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing records with no valid 2020 data...\n",
      "Records with valid 2020 data: 666643\n"
     ]
    }
   ],
   "source": [
    "print('Removing records with no valid 2020 data...')\n",
    "\n",
    "# Remove records for which no 2020 data exists\n",
    "df_2020 = mr_df[mr_df.T_20 != 'n.d.']\n",
    "\n",
    "# cells with no record for 2020 are of type string, need to convert first\n",
    "df_2020 = df_2020.astype({'M_20': int, 'F_20': int, 'T_20': int}) \n",
    "\n",
    "print('Records with valid 2020 data:', len(df_2020))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate clean municipality population dataset\n",
    "def updateTotal(x):\n",
    "    x['Totale'] = x[0]+x[1];\n",
    "    return x\n",
    "\n",
    "col_ETA = md_df_2019.columns[2]\n",
    "cols_pop = ['Totale Maschi', 'Totale Femmine']\n",
    "mpop = pd.DataFrame(data=md_df_2019[md_df_2019[col_ETA] != 999].groupby('Codice comune')[cols_pop].sum());\n",
    "mpop = mpop.apply(lambda x: updateTotal(x), axis=1)\n",
    "mpop;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm, trange\n",
    "from tqdm import tnrange, tqdm_notebook\n",
    "\n",
    "# Expand dataset to a single death per row\n",
    "#print('Expanding dataset to single record rows...')\n",
    "\n",
    "# columns to operate on\n",
    "#cols_M = ['M_15','M_16','M_17','M_18','M_19','M_20']\n",
    "#cols_F = ['F_15','F_16','F_17','F_18','F_19','F_20']\n",
    "#cols = ['M_15','M_16','M_17','M_18','M_19','M_20','F_15','F_16','F_17','F_18','F_19','F_20']\n",
    "#cols_TOTALE = ['T_15','T_16','T_17','T_18','T_19','T_20']\n",
    "\n",
    "# first copy the single-record rows to a new dataframe\n",
    "#df_2020 = df_2020_compact[(df_2020_compact['T_15'] + df_2020_compact['T_16'] + df_2020_compact['T_17'] +\n",
    "#                           df_2020_compact['T_18'] + df_2020_compact['T_19'] + df_2020_compact['T_20']) == 1];\n",
    "\n",
    "# then expand multi-record rows\n",
    "#for _, row in tqdm(df_2020_compact.iterrows(), total=(len(df_2020_compact)-len(df_2020))):\n",
    "#    if row[cols_TOTALE].sum() != 1:\n",
    "#        # this row represents multiple death records\n",
    "#        for i, cellin enumerate(row[cols_M]):\n",
    "#            # take each M_XX\n",
    "#            for j in range(1,cell+1):\n",
    "#                # create new records for each death\n",
    "#                df_2020 = df_2020.append(row, ignore_index=True)\n",
    "#                new_vals = [0,0,0,0,0,0,0,0,0,0,0,0]\n",
    "#                new_vals[i] = 1\n",
    "#                df_2020.loc[len(df_2020)-1,cols] = new_vals\n",
    "#        for i, cell in enumerate(row[cols_F]):\n",
    "#            # take each F_XX\n",
    "#            for j in range(1,cell+1):\n",
    "#                # create new records for each death\n",
    "#                df_2020 = df_2020.append(row, ignore_index=True)\n",
    "#                new_vals = [0,0,0,0,0,0,0,0,0,0,0,0]\n",
    "#                new_vals[i+6] = 1\n",
    "#                df_2020.loc[len(df_2020)-1,cols] = new_vals\n",
    "\n",
    "#print('Expanded dataset from %d to %d records' %(len(df_2020_compact), len(df_2020)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging population and geographical info...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ac56028b72249b6be90fb5e1bc16331",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=666643.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Reorganize the data so that features can be correlated\n",
    "print('Merging population and geographical info...')\n",
    "tqdm.pandas()\n",
    "\n",
    "def getGenderYearPopulationGeo(x):\n",
    "#    x['GENDER'] = 'Unknown';\n",
    "#    x['YEAR_OF_DEATH'] = 9999;\n",
    "    try:\n",
    "        # try to load info at 01-01-2019\n",
    "        x['POPULATION'] = mpop[mpop.index == x.COD_PROVCOM].Totale.iloc[0]\n",
    "    except:\n",
    "        # fallback to census 2011 (probably the municipality doesn't exist anymore)\n",
    "        x['POPULATION'] = md_df[md_df.COD_PROVCOM == x.COD_PROVCOM].POPOLAZIONE.iloc[0]\n",
    "    try:\n",
    "        x['LONGITUDE'] = geo_df[geo_df.istat == x.COD_PROVCOM].lng.iloc[0]\n",
    "        x['LATITUDE'] = geo_df[geo_df.istat == x.COD_PROVCOM].lat.iloc[0]\n",
    "    except:\n",
    "        x['LONGITUDE'] = 0.0\n",
    "        x['LATITUDE'] = 0.0\n",
    "\n",
    "#    if x[['M_15','M_16','M_17','M_18','M_19','M_20']].sum() == 1:\n",
    "#            x['GENDER'] = 'Male'\n",
    "#    elif x[['F_15','F_16','F_17','F_18','F_19','F_20']].sum() == 1:\n",
    "#            x['GENDER'] = 'Female'\n",
    "#    if (x.M_15 == 1 or x.F_15 == 1):\n",
    "#        x['YEAR_OF_DEATH'] = 2015\n",
    "#    elif (x.M_16 == 1 or x.F_16 == 1):\n",
    "#        x['YEAR_OF_DEATH'] = 2016\n",
    "#    elif (x.M_17 == 1 or x.F_17 == 1):\n",
    "#        x['YEAR_OF_DEATH'] = 2017\n",
    "#    elif (x.M_18 == 1 or x.F_18 == 1):\n",
    "#        x['YEAR_OF_DEATH'] = 2018\n",
    "#    elif (x.M_19 == 1 or x.F_19 == 1):\n",
    "#        x['YEAR_OF_DEATH'] = 2019\n",
    "#    elif (x.M_20 == 1 or x.F_20 == 1):\n",
    "#        x['YEAR_OF_DEATH'] = 2020\n",
    "    \n",
    "    return x\n",
    "\n",
    "df_2020 = df_2020.progress_apply(getGenderYearPopulationGeo,axis=1);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving aggregated dataset\n",
      "Aggregated dataset saved as mortalita_giornaliero_comune_20200504.xlsx\n"
     ]
    }
   ],
   "source": [
    "#cols = ['M_15','M_16','M_17','M_18','M_19','M_20',\n",
    "#            'F_15','F_16','F_17','F_18','F_19','F_20',\n",
    "#            'T_15','T_16','T_17','T_18','T_19','T_20']\n",
    "#df_2020 = df_2020.drop(labels=cols, axis=1)\n",
    "\n",
    "# Temporary: Remove records with Unknown gender\n",
    "#df_2020 = df_2020[df_2020.GENDER != 'Unknown'];\n",
    "\n",
    "# Serialize dataset\n",
    "print('Saving aggregated dataset')\n",
    "\n",
    "file_name = 'mortalita_giornaliero_comune_20200504.xlsx'\n",
    "df_2020.to_excel('mortalita_giornaliero_comune_20200504.xlsx')\n",
    "\n",
    "print('Aggregated dataset saved as %s' %file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
